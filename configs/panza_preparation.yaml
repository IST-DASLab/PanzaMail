defaults:
  - base
  - writer: summary
  - writer/prompting/retriever/faiss@retriever

batch_size: 8

email_dump_path: ${user.data_dir}/Sent.mbox
cleaned_emails_path: ${user.data_dir}/${user.username}_clean.jsonl
discarded_emails_dir: ${user.data_dir}/${user.username}/discarded_emails
summarized_emails_path: ${user.data_dir}/${user.username}_clean_summarized.jsonl

rag_db_dir: ${user.data_dir}

checkpoint: "microsoft/Phi-3-mini-4k-instruct" 
force_extract_clean_emails: false # If false, data will not be recreated if it already exists.

 # Parameters for train-test split, if required.
test_split: 0.
split_type: random # Options are 'random', 'chronological'.

# Parameters for RAG database.
rag_embedding_chunk_size: 3000
rag_embedding_chunk_overlap: 3000
rag_embedding_model: "sentence-transformers/all-mpnet-base-v2"
# For training with RAG, the relevant emails must be pre-cached, to avoid
# the costs of dynamically loading them during the data-loading. Thus, if
# RAG training (RAFT) is of interest, this should be set to a quite-hight 
# number, as it acts as an upper bound on the number of RAG emails that can
# be used during training time.
# The actual number of RAG emails used is also bounded by the setting
# in writer/prompting/email_prompting.
number_rag_emails_to_cache_with_train_data: 10