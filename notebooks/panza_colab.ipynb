{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Panza (with Mistral-7B)\n",
        "In this tutorial we will demonstrate how to create your personal email assistant by efficiently fine-tuning a Mistral-7B model on your own emails."
      ],
      "metadata": {
        "id": "UfpRIMZVUTrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation"
      ],
      "metadata": {
        "id": "kwxFd96OaEsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First things first, clone the Panza repository by running the following cell."
      ],
      "metadata": {
        "id": "q9kmBSKZWiWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IST-DASLab/PanzaMail.git\n",
        "%cd PanzaMail/scripts/"
      ],
      "metadata": {
        "id": "qqwRoXRaeExb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now run the cell bellow to install all the required packages (ignore warnings). This may take a while (up to 10 minutes), so please be patient!\n",
        "**You may get a message saying that some packages used by colab are updated and this might cause a crash. This is fine, you can simply dismiss the message!**"
      ],
      "metadata": {
        "id": "EYWaFUqMZI_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IST-DASLab/spops.git\n",
        "%cd spops\n",
        "!sed -i -e 's/sm_80/sm_75/g' setup.py\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "\n",
        "!pip install langdetect langchain langchain-community sentence-transformers faiss-cpu fire nltk gradio cmake packaging\n",
        "!pip install git+https://github.com/IST-DASLab/llm-foundry\n",
        "!pip install git+https://github.com/IST-DASLab/peft-rosa.git@grad_quant"
      ],
      "metadata": {
        "id": "WGEW2Tz4ZQN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, log into your `huggingface` account to access the Mistral-7B model and `wandb` account to enable logging."
      ],
      "metadata": {
        "id": "QhBhBs__ZfRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "kvZ18ysqZeyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download your sent emails\n",
        "**If you want to try Panza on a synthetic dataset, you can skip this step.**\n",
        "\n",
        "In order to train your personal email assistant, you need to download your sent emails. Please follow the instructions [here](https://github.com/IST-DASLab/PanzaMail?tab=readme-ov-file#step-0-download-your-sent-emails) and place the final `Send.mbox` file on your google drive in a `panza/` directory. Then run the following cell to mount your drive and copy the `mbox` file over to your local storage on colab."
      ],
      "metadata": {
        "id": "LWL-mBAoXKu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cp ../../drive/MyDrive/panza/Sent.mbox ../data/Sent.mbox"
      ],
      "metadata": {
        "id": "8u5dH9L6mmHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration\n",
        "Now from the left panel, open the file `PanzaMail/scripts/config.sh` and configure the parameters according to [this set of instructions](https://github.com/IST-DASLab/PanzaMail?tab=readme-ov-file#step-1-environment-configuration). Additionally, you would want to edit your prompt preambles (under `PanzaMail/prompt_preambles`).\n",
        "\n",
        "**Make sure to set `MODEL_PRECISION=4bit` and `PANZA_GENERATIVE_MODEL=\"mistralai/Mistral-7B-Instruct-v0.2\"`, since this is the only setting that fits into colab GPU.**"
      ],
      "metadata": {
        "id": "-1OCooJyWqqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Email Extraction\n",
        "**The cell bellow by default simply copies a synthetic set of emails to a specific location to be used later to prepare the dataset for fine-tuning. I case you want to use your own emails, uncomment the first line and comment the second line instead.**\n",
        "\n",
        "Run the following cell to extract emails from the `.mbox` file. Read more [here](https://github.com/IST-DASLab/PanzaMail?tab=readme-ov-file#step-2-extract-emails).\n"
      ],
      "metadata": {
        "id": "VYtgqgqjbALa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!./extract_emails.sh\n",
        "!source config.sh && cp ../data/Don_Quijote_Emails.jsonl ../data/${PANZA_USERNAME}_clean.jsonl"
      ],
      "metadata": {
        "id": "f77cV3c6b4Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation\n",
        "Run the following command to prepare your dataset (explained [here](https://github.com/IST-DASLab/PanzaMail?tab=readme-ov-file#step-3-prepare-dataset))."
      ],
      "metadata": {
        "id": "L0V775rncJ1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./prepare_dataset.sh LOAD_IN_4BIT=1 RUN_FP32=1"
      ],
      "metadata": {
        "id": "y3VTxbQTgn35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune the model on your data!\n",
        "Now you are ready to train your model! The following cell will start the training. This may take a while (up to a few hours, depending on your data size), so please be patient!"
      ],
      "metadata": {
        "id": "wjK0ch7HjAeE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbaOYNpmClVn"
      },
      "outputs": [],
      "source": [
        "!./train_rosa.sh CONFIG=../src/panza/finetuning/configs/rosa_panza_colab.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your Panza is ready!\n",
        "You can find your trained Panza model in `PanzaMail/checkpoints/models`. Consider moving the trained model to your google drive by running the following cell. Note that you are only storing a [RoSA adapter](https://arxiv.org/abs/2401.04679) on top of the base model, so it is not going to take up much space."
      ],
      "metadata": {
        "id": "UPD0R7i2sMNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r ../checkpoints/models ../../drive/MyDrive/panza/"
      ],
      "metadata": {
        "id": "OiNhL1XNsv3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can run the cell bellow to start giving instructions to your Panza!\n",
        "Please find the model path in `PanzaMail/checkpoints/models` and pass it in as the `MODEL` argument."
      ],
      "metadata": {
        "id": "HBq9RV2ttSKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_panza_cli.sh MODEL=/path/to/your/model/"
      ],
      "metadata": {
        "id": "XfGitk5ZBNaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
